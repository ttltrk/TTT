
---

#### [M](https://github.com/ttltrk/TTT/blob/master/menu.md) - [PY](https://github.com/ttltrk/TTT/blob/master/PY/PY.md) - [DS](https://github.com/ttltrk/TTT/blob/master/PY/PACKAGES/DATA_SCIENCE/DATA_SCIENCE.md)

---

### INTRO_TO_DS

---

* [LINK](https://courses.cognitiveclass.ai/courses/course-v1:BigDataUniversity+DS0101EN+2016/course/)

---

* [MODULE_1](#MODULE_1)
* [MODULE_2](#MODULE_2)
* [MODULE_3](#MODULE_3)
* [MODULE_4](#MODULE_4)
* [MODULE_5](#MODULE_5)

---

#### MODULE_1

##### What is data science?

- Data science is a process, not an event.
It is the process of using data
to understand different things,
to understand the world.
- For me, it's when you have a model,
or a hypothesis of a problem,
and you try to validate that hypothesis or model
with your data.
- Data science is the art of uncovering
the insights and trends that are hiding behind data.
- It's when you translate data into a story,
so you use the storytelling to generate insights.
And with these insights,
you can make strategic...
choices for a company or institution.
- Data science is a field about processes and systems,
to extract data from various forms,
whether it is an unstructured or structured form.
- Data science is the study of data,
like biological sciences are the study of biology;
physical sciences, it's the study of physical reactions.
Data is real, data has real properties,
and we need to study them,
if we're gonna work on them.
- Data science involves data and some science.
The definition, or the name,
came up in the 80s and 90s when some professors
were looking into the statistics curriculum,
and they thought it would be better to call it data science.
But what is data science?
I see data science as one's attempt to work with data
to find answers to questions that they are exploring.
In a nutshell, it's more about data
than it is about science.
If you have data, and you have curiosity,
and you're working with data,
and you're manipulating it,
you're exploring it,
the very exercise of going through analyzing data,
trying to get some answers from it, is data science.
Data science is relevant today
because we have tons of data available.
We used to worry about lack of data;
now we have a data deluge.
In the past, we didn't have algorithms;
now we have algorithms.
In the past, the software was expensive;
now it's open source and free.
In the past, we couldn't store large amounts of data;
now, for a fraction of the cost,
we can have gazillions of data sets for very low costs,
so the tools to work with data,
the very availability of data,
and the ability to store and analyze data,
it's all cheap, it's all available,
it's all ubiquitous, it's here.
There's never been a better time to be a data scientist.

##### There are many paths to data science

- Data science didn't really exist when I was growing up.
It's not something that I ever woke up
and said, "I want to be a data scientist when I grow up."
No, it didn't exist.
I didn't know I would be working in data science.
- When I grew up there wasn't
that field called data science.
And I think it's really new.
- Data science didn't exist until 2009, 2011.
Someone like DJ Patil or Andrew Gelman coined the term.
Before that there was statistics
and I didn't want to be any of those.
I wanted to be in business and
then I found data science a heck of a lot more interesting.
- I studied statistics, that's how I started.
I went through many different stages
in my life where I wanted to be a singer
and then a doctor and then I realized
that I was good at math.
So I chose an area that was focusing
quantitative analysis and from then
I do think that I wanted to work with data
not necessarily, data science as it's known today.
- The first time that I had contact with data science,
was when I was in my first year of mechanical engineering.
Strategical consulting firms,
they use data science to make decisions.
So, that was my first contact with data science.
- I had a complicated problem that I needed solved.
The usual techniques that we had at the time
couldn't help with the problem.
- I graduated with a math degree in the worst
possible time right after the economic crisis.
You actually had to be useful to get a job.
So I went and got a degree in statistics
and then I worked enough jobs that were
called data scientist that I suddenly became one.
- My undergraduate degree was in business
and I majored in politics, philosophy and economics.
And then I did a Masters in Business Analytics
at New York University at the Stern School of Business.
When I left my undergrad, the first company I joined,
it turned out that they were analyzing
electronic point of sale data for retail manufacturers.
And what we were doing was data science
but we only really started using that term much later.
In fact, I would say, four or five years ago
is when we started calling it analytics and data science.
- I had several options for my internship here in Canada
and one of the options was to work with data science.
I used to work in product development
but I think that was a good choice.
And then I started my internship with data science.
- I'm a civil engineer by training,
so all engineers work with data.
I would say the conventional use of data science
in my life started with transportation research.
I started building large models trying
to forecast traffic on streets,
trying to determine congestion
and greenhouse gas emissions or tailpipe emissions.
I think that's where my start was
and I started building these models when I was
a graduate student at the University of Toronto.
I started working with very large data sets
looking at household samples of 150,000 households,
half a million trips and that too,
I'm speaking from mid-nineties,
when this was supposed to be a very large data set
but not in today's terms but that's how I started.
I continued working with it and then I moved
to McGill University where I was a professor
of transportation engineering and I built
even bigger data models that involved data and analytics.
So I would say, yes transportation research
brought me to data science.

##### Any advice for new data scientist

- My advice to an aspiring data scientist is to be curious,
extremely argumentative,
judgmental.
Curiosity is absolutely must.
If you're not curious,
you would not know what to do with the data.
Judgmental because if you do not have
preconceived notions about things,
you wouldn't know where to begin.
Argumentative because if you can argue
then you can plead a case,
at least you can start somewhere.
And then you learn from data
and then you modify your assumptions and hypothesis,
and your data would help you learn.
And you may start at the wrong point,
you may say that I thought I believed this
but now with data I know this,
so this allows you a learning process.
So curiosity, being able to take a position,
strong position, and then moving forward with it.
The other thing that a data scientist would need is
some comfort and flexibility with analytics platforms.
Some software, some computing platform but that's secondary.
The most important thing is curiosity
and the ability to take positions.
Once you have done that,
once you've analyzed, then you've got some answers.
And that's the last thing that a data scientist needs
and that is the ability to tell a story.
That once you have your analytics,
once you have your tabulations,
now you should be able to tell a great story from it.
Because if you don't tell a great story from it,
your findings will remain hidden,
it will remain buried, nobody would know,
but your rise to prominence is pretty much relying on your
ability to tell great stories.
A starting point would be to see
what is your competitive advantage?
Do you want to be a data scientist in any field
or a specific field because
let's say you want to be a data scientist and work for an
IT firm or a web-based or internet-based firm.
Then you need a different set of skills.
And if you want to be a data scientist for
let's say in the health industry,
then you need different sets of skills.
So figure out first what your interest is
and what is your competitive advantage.
Your competitive advantage is not
necessarily going to be your analytical skills.
Your competitive advantage is your understanding of
some aspect of life where you exceed
beyond others in understanding that.
Maybe it's film, maybe it's retail,
maybe it's health, maybe it's computers.
Once you have figured out where your expertise lies,
then you start acquiring analytical skills,
what platforms to learn.
And those platforms, those tools would be specific to the
industry that you're interested in.
And then once you have got some proficiency in the tools,
the next thing would be to apply your skills to
real problems and then tell rest of the world
what you can do with it.

##### What is the cloud?

- Cloud is a, it's a godsend for data scientists.
Primarily because you're able to take the,
or you take your data, take your information
and put it in the cloud,
put it in the central storage system.
It allows you to bypass the physical limitations
of the computers and the systems you're using
and it allows you to deploy the analytics
and storage capacities of advanced machines
that do not necessarily have to be your machine
or your company's machine.
Cloud allows you not just to store large amounts of data
on servers somewhere in California or in Nevada,
but it also allows you to deploy very advanced
computing algorithms and the ability to do
high performance computing
using machines that are not yours.
So, think of it as you have some information,
you can't store it, so you send it to storage space,
let's call it cloud, and the algorithms that you need to use
you don't have them with you, but then on the cloud
you have those algorithms available.
So, what you do, is you deploy those algorithms
on very large data sets and you're able to do it
even though your own systems, your own machines,
your own computing environments
were not allowing you to do so.
So, cloud is beautiful.
And, the other thing that cloud is beautiful for
is that it allows multiple entities
to work with same data at the same time.
So, you can be working with the same data
that your colleagues in, say, Germany,
and another team in India, and another team in Ghana,
they are collectively working
and they are able to do so because the information
and the algorithms and the tools and the answers
and the results, whatever they needed
is available at a central place.
Which we call cloud, so cloud is beautiful.
At the Big Data University which is an IBM initiative,
we have these courses people can take
and learn about data science,
but at the same time we provide this cloud based environment
for not only analytics,
but also for working with big and small data.
So one of the products that is integrated
with Big Data University is Data Scientist Workbench.
Data Scientist Workbench is an internet based solution,
you log in and the moment you log in,
you now have access to some
very advanced computing environment.
As simple as R and Rstudio and data
and algorithms to define the data set using OpenRefine,
but also the ability to work with very large data sets
using technologies like Spark.
So, the advantage of working with Data Scientist Workbench
is not only that you have the ability to work with
these advanced algorithms and two computing platforms,
but you also have the ability to work with
very large data sets because Spark
is integrated and it's all in the cloud,
you don't have to maintain it,
you don't have to download it,
you don't have to worry about updating it.
All is being done for you in the cloud
by the Data Scientist Workbench.

#####

[^^^](#INTRO_TO_DS)

---

#### MODULE_2

##### A day in the life of a data science person

- I've built a recommendation engine before
as part of a large organization and worked
through all types of engineers and accounted
for different parts of the problem.
It's one of the one's I'm most happy with
because ultimately I came up with the very simple solution
that was easy to understand from all levels,
from the executives to the engineers and developers.
Ultimately it was just as efficient
as something really complex that I could have
spent a lot more time on.
- Back in the university we have a problem
that we wanted to predict algal bloom.
This algae bloom could cause rising toxicity of the water
and it could cause problems to the water treatment company.
We couldn't predict it with our chemical engineering
background so we used artificial neural-networks to predict
when this bloom will occur.
So the water treatment companies could
better handle this problem.
- In Toronto the public transit is operated by
Toronto Transit Commission.
We call them TTC.
It's one of the largest transit authorities
in the region in North America.
And one day they contacted me and said, 'we have a problem'.
And I said okay, what's the problem.
They said, 'well we have complaints data
and we would like to analyze it and we need your help'.
I said fine I'll be very happy to help.
So I said how many complaints do you have?
They said, 'a few'.
I said how many?
'Maybe half a million'.
I said well let's start working with it.
So I got the data and I started analyzing it.
So basically they have done a great job at
keeping the data, some data in tabular format
other was unstructured data.
And in that case tabular data
was when the complaint arrived, who received it,
what was the type of the complaint, was it resolved,
whose fault was it.
And the unstructured part of it
was the exchange of emails and faxes.
So imagine looking at half a million exchanges of emails
and trying to get some answer from it.
So I started working with it
and the first thing I wanted to know is
why would people complain and is there a pattern.
Are there some days where there are
more complaints than others?
And I looked at the data and I analyzed
it in all different formats and I couldn't find
what the impetus for complaints being higher
on a certain day and lower on others.
And it continued for maybe a month of so
and then one day I was getting off the bus in Toronto
and I was still thinking about it
and I stepped out without looking on the ground
and I stepped into a puddle,
puddle of water.
And now I was sort of ankle deep into water
and it was just one foot wet and the other dry
and I was extremely annoyed.
And I was walking back and then it hit me
and I said well wait a second.
Today it rained unexpectedly and I wasn't prepared for it.
That's why I'm wet and I wasn't looking for it.
What if there's a relationship between
extreme weather and the type of complaints TTC receives?
So I went to the Environment Canada's website
and I got data on rain and precipitation,
wind and the like.
And there I found something very interesting.
The ten most excessive days for complaints,
the ten days were people complain the most
were the days when the weather was bad.
It was unexpected rain, an extreme drop in temperature,
too much snow, a very windy day.
So I went back to the TTC's executives
and I said, I've got good news and bad news.
I said, the good news is I know why people
would complain excessively on certain days.
I know the reason for it.
The bad news is there's nothing you can do about it.

##### R versus Python

As I have an engineering background,
I started programming with C, then I went to Matlab,
and eventually to Python.
I usually use Matlab, C, and C++,
but for data science I use Python.
- R and Python.
- R.
- I'm an R evangelist.
I was at the useR Conference last year
and I think it's got one of the best communities,
I'm also very fond of SQL and I think people don't spend
enough time appreciating it in its various incarnations.
- I primarily work with R and Stata.
I do not work a lot with big data so for the kind
of data sets I have, there are a few million observations,
even the hundreds of millions of observations
then I can work with with the existing Stata and R and SPSS,
I don't have a problem with it,
but as I said, if I were to work with large data sets,
I would use different tools.
My preferred tools are the three; R, Stata, and SPSS.
I also work with spacial data a lot
so these are data sets which have a geographical
component to it, so imagine 40 million Californians
and 40 million people, some of them in California,
some of them in the neighboring states,
and what if I know the exact home address
of each and everyone of them and where they work.
And that would be an amazing GIS,
spacial geographic information systems database.
So I work with those as well and my tool that I use
is called Maptitude and MapInfo,
these are the two I use the most.

##### Data science tools and technology

- I really enjoy regression.
I'd say regression was maybe one of the first concepts that
really helped me understand data, so I enjoy regression.
- I really like data visualization.
I think it's a key element for people to get
across their message to people
that don't understand that well what data science is.
- Artificial neural networks.
- I'm really passionate about neural networks
because we have a lot to learn from nature
so when we are trying to mimic our brain,
I think that we can do some applications with this behavior,
this biological behavior in algorithms.
- Data visualization with R, I love to do this.
- Nearest neighbor, it's the simplest,
but it just gets the best results so many more times,
than some overblown, overworked algorithm
that's just as likely to over fit
as it is to make a good fit.
- So, structured data is more like tabular data,
things that you're familiar with in Microsoft Excel format,
you've got rows and columns,
and that's called structured data.
Unstructured data is basically data that is coming from
mostly from web, where it's not tabular.
It is not in rows and columns, it's text.
Sometimes it's video and audio.
You would have to deploy more sophisticated algorithms
to extract data.
In fact, a lot of times, we take unstructured data
and spend a great deal of time and effort to get
some structure out of it and then analyze it.
If you have something which just fits nicely into
tables and columns and rows go ahead.
That's your structured data,
but if you see if it's a weblog,
or if you're trying to get information out of webpages,
and you've got a gazillion webpages,
that's unstructured data,
that would require a little bit more effort
to get information out of it.
Machine learning is basically a set of these advanced tools
people use to find answers.
I'm not a big fan of machine learning,
and I'll give you my bias right now.
Imagine there's an island
and there are about 45,000 people who live on that island.
It's cut off from the rest of the world,
nobody can swim into the island, or swim out of the island.
Now imagine that island had a murder,
and you're the detective who's been tasked
with finding who the culprit is.
Now, there's various approaches you can take.
One approach is you say, well, whoever killed this person
is on this island.
So there are 45,000 people and there are 45,000 suspects.
I'm going to go one by one asking each person
until I find the suspect, right.
That's machine learning, because you have no other reason,
no other assumptions, no other hypothesis, no other feeling.
You say, I don't know anything.
I'm just going to throw everything into my model
and see who the culprit is.
Sometimes you get to the culprit, sometimes you don't,
but it would take time.
Machine learning is basically saying when you do not have
many assumptions about your data, and you're short of
knowing a lot about your data,
you just throw everything into this model,
and see what comes out of it.
It's more of a black box approach.
I know that a large number of professionals live by it.
I, on the other hand, like to look at data with my own
preconceived notions, because it is said, a data scientist
is someone who is very judgmental.
That person, a data scientist is one who has an opinion
about data.
Who has an opinion about the phenomena they're learning,
or they're investigating.
They cannot simply believe
that I'm going to have a kitchen sink approach,
I'm going to dump everything in the model.
Machine learning is basically saying, dump everything,
see what comes out of it.
There are thousands of books written on regression,
and millions of lectures delivered on regression.
And I always feel that they don't do a good job
of explaining regression, because they get into data
and models and statistical distributions.
Let's forget about it, let me explain regression
in the simplest possible terms.
If you have ever taken a cab ride, a taxi ride,
you understand regression.
Here's how it works.
The moment you sit in a cab ride, in a cab,
you see that there's a fixed amount there, it says 2 dollars 50 cents, $2.50
You rather that the cab moves or you get off,
this is what you owe to the driver,
the moment you step into a cab.
That's a constant, you have to pay that amount,
if you have stepped into a cab.
Then as it starts moving, for every meter or 100 meters,
the fare increases by a certain amount.
So, there's a fraction, there's a relationship
between distance and the amount you would pay,
above and beyond that constant.
If you're not moving, and you're stuck in traffic,
then every additional minute, you have to pay more.
As the minutes increase, your fare increases,
as the distance increases, your fare increases,
and while all this is happening, you've already
paid a base fare, which is the constant.
This is what regression is.
Regression tells you what the base fare is
and what is the relationship between time
and the fare you have paid
and the distance you have traveled
and the fare you have paid.
Because in the absence of knowing those relationships,
and just knowing how much people traveled for,
and how much they paid,
regression allows you to compute
that constant that you didn't know it was 2.50,
and it would compute the relationship between the fare
and the distance, and the fare and the time.
That's a regression.

[^^^](#INTRO_TO_DS)

---

#### MODULE_3

[^^^](#INTRO_TO_DS)

---

#### MODULE_4

[^^^](#INTRO_TO_DS)

---

#### MODULE_5

[^^^](#INTRO_TO_DS)

---
